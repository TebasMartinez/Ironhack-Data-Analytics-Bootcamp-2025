{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Aggregation-and-Grouping\" data-toc-modified-id=\"Data-Aggregation-and-Grouping-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Aggregation and Grouping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Aggregation\" data-toc-modified-id=\"Aggregation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Aggregation</a></span></li><li><span><a href=\"#Grouping\" data-toc-modified-id=\"Grouping-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Grouping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Iterating-GroupBy-object\" data-toc-modified-id=\"Iterating-GroupBy-object-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Iterating GroupBy object</a></span></li><li><span><a href=\"#groups\" data-toc-modified-id=\"groups-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span><code>groups</code></a></span></li><li><span><a href=\"#size\" data-toc-modified-id=\"size-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span><code>size</code></a></span></li><li><span><a href=\"#get_group()\" data-toc-modified-id=\"get_group()-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span><code>get_group()</code></a></span></li><li><span><a href=\"#Applying-aggregations\" data-toc-modified-id=\"Applying-aggregations-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Applying aggregations</a></span></li><li><span><a href=\"#Multiple-Aggregations\" data-toc-modified-id=\"Multiple-Aggregations-1.2.6\"><span class=\"toc-item-num\">1.2.6&nbsp;&nbsp;</span>Multiple Aggregations</a></span></li><li><span><a href=\"#Grouping-by-Multiple-Variables\" data-toc-modified-id=\"Grouping-by-Multiple-Variables-1.2.7\"><span class=\"toc-item-num\">1.2.7&nbsp;&nbsp;</span>Grouping by Multiple Variables</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Summary</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#ðŸ’¡-Check-for-understanding\" data-toc-modified-id=\"ðŸ’¡-Check-for-understanding-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>ðŸ’¡ Check for understanding</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation and Grouping \n",
    "\n",
    "Data aggregation and grouping are fundamental operations in data analysis. They involve combining multiple pieces of data into a single result. For instance, you may want to group data by certain variables and then calculate summary statistics like count, mean, sum, or standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/titanic_train.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "Aggregation in pandas involves applying a function to a dataset, transforming multiple values into a single value. pandas provides various aggregation functions, including:\n",
    "\n",
    "- `mean()`: Compute the arithmetic mean.\n",
    "- `sum()`: Compute the sum of values.\n",
    "- `min()`: Compute the minimum value.\n",
    "- `max()`: Compute the maximum value.\n",
    "- `count()`: Count the number of non-null values.\n",
    "- `std()`: Compute the standard deviation.\n",
    "\n",
    "For instance, to find the mean value of a numerical column, use the `mean()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.204207968574636"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "Grouping is the process of splitting the data into groups based on certain criteria. The `groupby()` function is used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x13d812750>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('Sex')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating GroupBy object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby()` function in pandas returns a `GroupBy` object that can be iterated over. Each iteration provides a tuple where the first item is the group identifier and the second item is the data in that group as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group name: female\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "..           ...       ...     ...   \n",
      "880          881         1       2   \n",
      "882          883         0       3   \n",
      "885          886         0       3   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "8        2            347742  11.1333   NaN        S  \n",
      "9        0            237736  30.0708   NaN        C  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "880      1            230433  26.0000   NaN        S  \n",
      "882      0              7552  10.5167   NaN        S  \n",
      "885      5            382652  29.1250   NaN        Q  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "\n",
      "[314 rows x 12 columns]\n",
      "Group name: male\n",
      "     PassengerId  Survived  Pclass                            Name   Sex  \\\n",
      "0              1         0       3         Braund, Mr. Owen Harris  male   \n",
      "4              5         0       3        Allen, Mr. William Henry  male   \n",
      "5              6         0       3                Moran, Mr. James  male   \n",
      "6              7         0       1         McCarthy, Mr. Timothy J  male   \n",
      "7              8         0       3  Palsson, Master. Gosta Leonard  male   \n",
      "..           ...       ...     ...                             ...   ...   \n",
      "883          884         0       2   Banfield, Mr. Frederick James  male   \n",
      "884          885         0       3          Sutehall, Mr. Henry Jr  male   \n",
      "886          887         0       2           Montvila, Rev. Juozas  male   \n",
      "889          890         1       1           Behr, Mr. Karl Howell  male   \n",
      "890          891         0       3             Dooley, Mr. Patrick  male   \n",
      "\n",
      "      Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0    22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "4    35.0      0      0            373450   8.0500   NaN        S  \n",
      "5     NaN      0      0            330877   8.4583   NaN        Q  \n",
      "6    54.0      0      0             17463  51.8625   E46        S  \n",
      "7     2.0      3      1            349909  21.0750   NaN        S  \n",
      "..    ...    ...    ...               ...      ...   ...      ...  \n",
      "883  28.0      0      0  C.A./SOTON 34068  10.5000   NaN        S  \n",
      "884  25.0      0      0   SOTON/OQ 392076   7.0500   NaN        S  \n",
      "886  27.0      0      0            211536  13.0000   NaN        S  \n",
      "889  26.0      0      0            111369  30.0000  C148        C  \n",
      "890  32.0      0      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[577 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each group\n",
    "for name, group in grouped:\n",
    "    print(f\"Group name: {name}\")\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of groups by gender (`len(grouped)`) is equal to the number of unique elements in that category.\n",
    "\n",
    "df['Sex'].nunique() == len(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `groups`\n",
    "The `groups` attribute of a pandas `GroupBy` object is a dictionary. The keys of this dictionary are the computed unique groups and the corresponding values are the axis labels belonging to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female': [1, 2, 3, 8, 9, 10, 11, 14, 15, 18, 19, 22, 24, 25, 28, 31, 32, 38, 39, 40, 41, 43, 44, 47, 49, 52, 53, 56, 58, 61, 66, 68, 71, 79, 82, 84, 85, 88, 98, 100, 106, 109, 111, 113, 114, 119, 123, 128, 132, 133, 136, 140, 141, 142, 147, 151, 156, 161, 166, 167, 172, 177, 180, 184, 186, 190, 192, 194, 195, 198, 199, 205, 208, 211, 215, 216, 218, 229, 230, 233, 235, 237, 240, 241, 246, 247, 251, 254, 255, 256, 257, 258, 259, 264, 268, 269, 272, 274, 275, 276, ...], 'male': [0, 4, 5, 6, 7, 12, 13, 16, 17, 20, 21, 23, 26, 27, 29, 30, 33, 34, 35, 36, 37, 42, 45, 46, 48, 50, 51, 54, 55, 57, 59, 60, 62, 63, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 107, 108, 110, 112, 115, 116, 117, 118, 120, 121, 122, 124, 125, 126, 127, 129, 130, 131, 134, 135, 137, 138, 139, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, ...]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `size`\n",
    "\n",
    "The `size` attribute of a pandas `GroupBy` object returns a Series giving the size (i.e., the number of items) of each group. This is like applying the `count()` function to each group, but `size` includes `NaN` values and `count` does not. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    314\n",
       "male      577\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_group()`\n",
    "\n",
    "The `get_group` method is used to select a single group from a `GroupBy` object as a DataFrame. You provide the name of the group you want to select as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.get_group('female').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is split into groups, you need a way to represent each group in the resulting output. That's where aggregation functions come in.\n",
    "\n",
    "For example, if you group a DataFrame by a categorical variable (like 'City'), you'll end up with a separate group for each unique city in your data. But how do you want to represent each city in your result? Do you want the mean of another variable (like 'Sales') for each city? The sum? The maximum? This is what the aggregation function determines.\n",
    "\n",
    "When you apply an aggregation function after a `groupby()`, pandas applies that function to each group separately and then combines the results into a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns()\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1363\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m-> 1363\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1365\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "df.groupby('Sex').mean() # Get the mean of each variable grouped by Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    27.915709\n",
       "male      30.726645\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find the average age of the passengers grouped by their gender\n",
    "\n",
    "df.groupby('Sex')['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Aggregations\n",
    "\n",
    "You can perform multiple aggregations at once using the `agg()` function. \n",
    "\n",
    "For example, let's find the count, mean, and standard deviation of the age of passengers, grouped by their gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std\n",
       "Sex                                \n",
       "female    261  27.915709  14.110146\n",
       "male      453  30.726645  14.678201"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Sex')['Age'].agg(['count', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by Multiple Variables\n",
    "\n",
    "You can group by multiple variables by passing a list to the `groupby()` function.\n",
    "\n",
    "For example, let's find the average age of passengers grouped by their gender and whether they survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0           25.046875\n",
       "        1           28.847716\n",
       "male    0           31.618056\n",
       "        1           27.276022\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Sex', 'Survived'])['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aggregation involves applying a function to a dataset that reduces multiple values into a single value. Common aggregation functions in pandas include `mean()`, `sum()`, `min()`, `max()`, `count()`, and `std()`.\n",
    "- Grouping in pandas is done using the `groupby()` function, which splits data into groups based on certain criteria. The grouped data can then be aggregated separately.\n",
    "    - A `GroupBy` object can be iterated over, with each iteration yielding a tuple where the first item is the group identifier, and the second item is the data in that group as a DataFrame.\n",
    "    - The `groups` attribute of a `GroupBy` object is a dictionary where the keys are the computed unique groups, and the corresponding values are the axis labels belonging to each group.\n",
    "    - The `size` attribute of a `GroupBy` object returns a Series giving the size of each group. Unlike the `count()` function, `size` includes `NaN` values.\n",
    "    - The `get_group()` method of a `GroupBy` object allows for the selection of a single group as a DataFrame.\n",
    "- After a `groupby()` operation, an aggregation function is necessary to represent each group in the resulting output.\n",
    "- Multiple aggregations can be performed at once using the `agg()` function.\n",
    "- Grouping can be done by multiple variables by passing a list to the `groupby()` function. This can be helpful when you want to analyze your data at different levels of granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Check for understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using the Titanic dataset (`'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/titanic_train.csv'`), perform the following operations and **write your conclusions after each step**:\n",
    "\n",
    "- Calculate the number, mean, and standard deviation of the 'Fare' paid by passengers, grouped by their 'Sex'.\n",
    "\n",
    "- Determine the number of survivors and non-survivors by class (use 'Pclass' variable).\n",
    "\n",
    "- Determine the number of survivors and non-survivors by gender.\n",
    "\n",
    "- Use the `get_group` method to select the group of 1st Class passengers and display the first 5 rows of this group. Then, group by 'Survived' within the first class group, and calculate the average fare.\n",
    "\n",
    "- Create a new column 'AgeGroup' . This column should categorize passengers as 'Child' (age <= 12), 'Teen' (12 < age <=18), 'Adult' (18 < age <= 60), and 'Senior' (age > 60). Then, find out how many survivors are there in each age group.\n",
    "\n",
    "- BONUS: calculate the survival rates within each age group in percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>314</td>\n",
       "      <td>44.479818</td>\n",
       "      <td>57.997698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>577</td>\n",
       "      <td>25.523893</td>\n",
       "      <td>43.138263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std\n",
       "Sex                                \n",
       "female    314  44.479818  57.997698\n",
       "male      577  25.523893  43.138263"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number, mean, and standard deviation of the 'Fare' paid by passengers, grouped by their 'Sex'.\n",
    "df.groupby(\"Sex\")[\"Fare\"].agg(['count', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  Pclass\n",
       "0         1          80\n",
       "          2          97\n",
       "          3         372\n",
       "1         1         136\n",
       "          2          87\n",
       "          3         119\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of survivors and non-survivors by class (use 'Pclass' variable).\n",
    "df.groupby([\"Survived\", \"Pclass\"])[\"Pclass\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  Sex   \n",
       "0         female     81\n",
       "          male      468\n",
       "1         female    233\n",
       "          male      109\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of survivors and non-survivors by gender.\n",
    "df.groupby([\"Survived\", \"Sex\"])[\"Sex\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  Sex   \n",
       "0         female     81\n",
       "          male      468\n",
       "1         female    233\n",
       "          male      109\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also possible:\n",
    "df.groupby([\"Survived\", \"Sex\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    64.684007\n",
       "1    95.608029\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the get_group method to select the group of 1st Class passengers and display the first 5 rows of this group. \n",
    "# Then, group by 'Survived' within the first class group, and calculate the average fare.\n",
    "df.groupby(\"Pclass\").get_group(1).groupby(\"Survived\")[\"Fare\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'AgeGroup' . This column should categorize passengers as 'Child' (age <= 12), 'Teen' (12 < age <=18), \n",
    "# 'Adult' (18 < age <= 60), and 'Senior' (age > 60). Then, find out how many survivors are there in each age group.\n",
    "import numpy as np\n",
    "\n",
    "AgeGroup = []\n",
    "for x in df[\"Age\"]:\n",
    "    if x <= 12:\n",
    "        AgeGroup.append(\"Child\")\n",
    "    elif x <= 18:\n",
    "        AgeGroup.append(\"Teen\")\n",
    "    elif x <= 60:\n",
    "        AgeGroup.append(\"Adult\")\n",
    "    elif x > 60:\n",
    "        AgeGroup.append(\"Senior\")\n",
    "    else:\n",
    "        AgeGroup.append(np.nan)\n",
    "df[\"AgeGroup\"] = AgeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Child',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Child',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Child',\n",
       " 'Child',\n",
       " 'Child',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Child',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Teen',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Senior',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " nan,\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Child',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Teen',\n",
       " nan,\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Child',\n",
       " nan,\n",
       " nan,\n",
       " 'Child',\n",
       " nan,\n",
       " 'Senior',\n",
       " 'Teen',\n",
       " 'Child',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Senior',\n",
       " 'Child',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Teen',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " 'Adult',\n",
       " nan,\n",
       " 'Adult',\n",
       " 'Adult']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same in a separate function\n",
    "def create_agegroup(agecolumn):\n",
    "    agegrouplist = []\n",
    "    for x in df[\"Age\"]:\n",
    "        if x <= 12:\n",
    "            agegrouplist.append(\"Child\")\n",
    "        elif x <= 18:\n",
    "            agegrouplist.append(\"Teen\")\n",
    "        elif x <= 60:\n",
    "            agegrouplist.append(\"Adult\")\n",
    "        elif x > 60:\n",
    "            agegrouplist.append(\"Senior\")\n",
    "        else:\n",
    "            agegrouplist.append(np.nan)\n",
    "    return agegrouplist\n",
    "\n",
    "newcolumn = create_agegroup(df[\"Age\"])\n",
    "newcolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Adult\n",
       "1      Adult\n",
       "2      Adult\n",
       "3      Adult\n",
       "4      Adult\n",
       "       ...  \n",
       "886    Adult\n",
       "887    Adult\n",
       "888    Adult\n",
       "889    Adult\n",
       "890    Adult\n",
       "Name: Age, Length: 891, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same with .apply() function\n",
    "def create_agegroupapply(agevalue):\n",
    "    if x <= 12:\n",
    "        return \"Child\"\n",
    "    elif x <= 18:\n",
    "        return \"Teen\"\n",
    "    elif x <= 60:\n",
    "        return \"Adult\"\n",
    "    elif x > 60:\n",
    "        return\"Senior\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "newgroup = df[\"Age\"].apply(create_agegroupapply)\n",
    "\n",
    "newgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked AgeGroup  \n",
       "0        0         A/5 21171   7.2500   NaN        S    Adult  \n",
       "1        0          PC 17599  71.2833   C85        C    Adult  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S    Adult  \n",
       "3        0            113803  53.1000  C123        S    Adult  \n",
       "4        0            373450   8.0500   NaN        S    Adult  \n",
       "..     ...               ...      ...   ...      ...      ...  \n",
       "886      0            211536  13.0000   NaN        S    Adult  \n",
       "887      0            112053  30.0000   B42        S    Adult  \n",
       "888      2        W./C. 6607  23.4500   NaN        S      NaN  \n",
       "889      0            111369  30.0000  C148        C    Adult  \n",
       "890      0            370376   7.7500   NaN        Q    Adult  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgeGroup  Survived\n",
       "Adult     0           338\n",
       "          1           215\n",
       "Child     0            29\n",
       "          1            40\n",
       "Senior    0            17\n",
       "          1             5\n",
       "Teen      0            40\n",
       "          1            30\n",
       "Name: AgeGroup, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"AgeGroup\", \"Survived\"])[\"AgeGroup\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate for children: 57.97%\n",
      "Survival rate for teens: 42.86%\n",
      "Survival rate for adults: 38.88%\n",
      "Survival rate for seniors: 22.73%\n"
     ]
    }
   ],
   "source": [
    "# BONUS: calculate the survival rates within each age group in percentages.\n",
    "Adult_Survival_Rate = round(((df.groupby([\"AgeGroup\", \"Survived\"])[\"AgeGroup\"].count()[\"Adult\"][1] / df.groupby([\"AgeGroup\"])[\"AgeGroup\"].count()[\"Adult\"]) * 100),2)\n",
    "Child_Survival_Rate = round(((df.groupby([\"AgeGroup\", \"Survived\"])[\"AgeGroup\"].count()[\"Child\"][1] / df.groupby([\"AgeGroup\"])[\"AgeGroup\"].count()[\"Child\"]) * 100),2)\n",
    "Senior_Survival_Rate = round(((df.groupby([\"AgeGroup\", \"Survived\"])[\"AgeGroup\"].count()[\"Senior\"][1] / df.groupby([\"AgeGroup\"])[\"AgeGroup\"].count()[\"Senior\"]) * 100),2)\n",
    "Teen_Survival_Rate = round(((df.groupby([\"AgeGroup\", \"Survived\"])[\"AgeGroup\"].count()[\"Teen\"][1] / df.groupby([\"AgeGroup\"])[\"AgeGroup\"].count()[\"Teen\"]) * 100),2)\n",
    "\n",
    "print(f\"Survival rate for children: {Child_Survival_Rate}%\")\n",
    "print(f\"Survival rate for teens: {Teen_Survival_Rate}%\")\n",
    "print(f\"Survival rate for adults: {Adult_Survival_Rate}%\")\n",
    "print(f\"Survival rate for seniors: {Senior_Survival_Rate}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "537.273px",
    "left": "420px",
    "top": "110.824px",
    "width": "426.996px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
